{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNsR4GD9X5Edfp4/5Nz+9z/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pimentell/timeSeriesAnalysysAIQ/blob/main/Time_Series_AQI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# __Neural Nets for Time Series Analysis.__"
      ],
      "metadata": {
        "id": "Vs2Sv9mdBWbW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### __Import Modules and Python Dependencies__"
      ],
      "metadata": {
        "id": "qqSjHws-AuqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import datetime \n",
        "import IPython\n",
        "import IPython.display\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "nzDqbP7vBVck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### __Creating Directory and Download Data from Google Drive__"
      ],
      "metadata": {
        "id": "mfO-mrv19sMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf sample_data\n",
        "!gdown 1GN1P7mrqLIIqIIfVtLluCW-s_PSgQf4E\n",
        "!mkdir data\n",
        "!unzip data.zip  -d data "
      ],
      "metadata": {
        "id": "ZJQILC07v6RW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# __Air Quality Data in India (2015 - 2020)__\n",
        "\n",
        "### Multivariate Time Series\n",
        "#### __Import Data__"
      ],
      "metadata": {
        "id": "-IFChY-U9i0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"data/city_day.csv\", parse_dates=True)\n",
        "data['Date'] = data['Date'].apply(pd.to_datetime)\n",
        "data.set_index('Date',inplace=True)"
      ],
      "metadata": {
        "id": "7dyuRVcQyFy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- __PM2.5 (Particulate Matter 2.5-micrometer)__: measured in ug / m3 (micrograms per cubic meter of air)\n",
        "- __PM10 (Particulate Matter 10-micrometer)__: measured in ug / m3 (micrograms per cubic meter of air)\n",
        "- __SO2 (Sulphur Dioxide)__:measured in ug / m3 (micrograms per cubic meter of air)\n",
        "- __NOx (Any Nitric x-oxide)__: measured in ppb (parts per billion)\n",
        "- __NH3 (Ammonia)__: measured in ug / m3 (micrograms per cubic meter of air)\n",
        "- __CO (Carbon Monoxide)__:CO is measured in mg / m3 (milligrams per cubic meter of air)\n",
        "- __O3 (Ozone or Trioxygen)__: O3 is measured in ug / m3 (micrograms per cubic meter of air)\n",
        "\n",
        "- __AQI__: AIR Quality Index\n",
        "![AQI](https://drive.google.com/uc?id=1zdwS3uFmkytjB4xlDOImnbnsVCaDAYzp)"
      ],
      "metadata": {
        "id": "RMzMWE5R_Uph"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### __Calidad del Aire por Ciudad__\n"
      ],
      "metadata": {
        "id": "PYqDs6MKII0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[[\"City\", \"AQI\"]].groupby([\"City\"]).mean().plot.barh(figsize=(20,10))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4qHPr10-IEqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### __Correlación calidad del aire y variables predictivas__"
      ],
      "metadata": {
        "id": "V9bFSu9iIMVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[data.City == \"Delhi\"] # Solo para nueva Delhi\n",
        "data[[\"AQI\"]].plot(figsize=(20,10))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "46wX1fHrOTHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_corr = data.corr()\\\n",
        "  .reset_index()[[\"index\", \"AQI\"]]\\\n",
        "  .sort_values(by = \"AQI\", ascending=False)\\\n",
        "  .rename(columns={\"index\":\"Variable\"})\n",
        "data_corr = data_corr[data_corr.Variable != \"AQI\"]\n",
        "data_corr.plot.bar(x=\"Variable\", figsize=(20,10))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iKwgHHGoIL0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### __Data Cleaning__"
      ],
      "metadata": {
        "id": "L7mEck8xGbYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Valores nulos por columna\n",
        "# Eliminamos variables que no son necesarias o no se encuentran dentro del calculo del Indice de Calidad del Aire: \n",
        "data = data.drop(columns = [\"Benzene\", \"Toluene\", \"Xylene\", \"City\", \"AQI_Bucket\"])\n",
        "data.isna().mean()"
      ],
      "metadata": {
        "id": "2ldzerbkGeWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " El tratamiento normal para los datos nulos es la imputación. \n",
        "\n",
        "- Mean\n",
        "- Median\n",
        "- Regression"
      ],
      "metadata": {
        "id": "iQi5DPzxHLZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.fillna(data.mean(), inplace = True)\n",
        "data.isna().mean()"
      ],
      "metadata": {
        "id": "o4b3vptaGuO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "plt.hist2d(data['PM10'], data['AQI'])\n",
        "plt.colorbar()\n",
        "plt.title(\"PM10 VS AQI\")\n",
        "plt.xlabel(\"PM10\")\n",
        "plt.ylabel('AQI')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EkvclEDbVdSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### __Preparación de los Datos__"
      ],
      "metadata": {
        "id": "2eoRsO-mRc2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.to_csv(\"clean_data.csv\", index = False)\n",
        "\n",
        "with open(\"clean_data.csv\") as f: \n",
        "  clean_data = f.read()\n",
        "\n",
        "lines = clean_data.split(\"\\n\")[:-1]\n",
        "header = lines[0].split(\",\")\n",
        "lines = lines[1:]\n",
        "\n",
        "aqi = np.zeros(len(lines),)\n",
        "raw_variables = np.zeros((len(lines), len(header)-1))\n",
        "\n",
        "for i, line in enumerate(lines): \n",
        "  values = [x for x in line.split(\",\")]\n",
        "  aqi[i] = values[-1]\n",
        "  raw_variables[i,:] = values[:-1]\n",
        "  "
      ],
      "metadata": {
        "id": "gtqKgrC4RgVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_train_samples = int(0.5 * len(raw_variables))\n",
        "num_val_samples = int(0.25 * len(raw_variables))\n",
        "num_test_samples = len(raw_variables) - num_train_samples - num_val_samples\n",
        "\n",
        "print(\"Entradas de entrenamiento: \", num_train_samples)\n",
        "print(\"Entradas de validation: \", num_val_samples)\n",
        "print(\"Entradas de test: \", num_test_samples)\n"
      ],
      "metadata": {
        "id": "-L7kLB2EVs8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalización de los datos \n",
        "mean = raw_variables[:num_train_samples].mean(axis=0)\n",
        "raw_variables -= mean\n",
        "std = raw_variables[:num_train_samples].std(axis=0)\n",
        "raw_variables /= std\n",
        "raw_variables[0]"
      ],
      "metadata": {
        "id": "wpj4sJFXY6L5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = raw_variables[:num_train_samples]\n",
        "val_x = raw_variables[num_train_samples:num_train_samples + num_val_samples]\n",
        "test_x = raw_variables[num_train_samples + num_val_samples:]"
      ],
      "metadata": {
        "id": "UmsQ__UcW0V4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = aqi[:num_train_samples]\n",
        "val_y = aqi[num_train_samples:num_train_samples + num_val_samples]\n",
        "test_y = aqi[num_train_samples + num_val_samples:]"
      ],
      "metadata": {
        "id": "wAVH4Yr9ab57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# __Basic Linear Regresion__"
      ],
      "metadata": {
        "id": "S2Eka3Y-3UYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "reg = LinearRegression().fit(train_x, train_y)\n",
        "R2 = reg.score(train_x, train_y)\n",
        "print(\"Coeficiente de Determinación: \", R2)"
      ],
      "metadata": {
        "id": "8u5gD1pczGP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_predict = reg.predict(train_x)\n",
        "test_predict = reg.predict(test_x)\n",
        "val_predict = reg.predict(val_x)\n",
        "\n",
        "rmse_train = sqrt(mean_squared_error(train_y, train_predict))\n",
        "rmse_test = sqrt(mean_squared_error(test_y, test_predict))\n",
        "print('Train RMSE: %.3f' % rmse_train)\n",
        "print('Test RMSE: %.3f' % rmse_test)"
      ],
      "metadata": {
        "id": "KmneEu0Y0cbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = np.arange(0,len(test_y),1)\n",
        "\n",
        "plt.figure(figsize=(20,4))\n",
        "plt.title(\"Test DataSet\")\n",
        "plt.plot(t,test_y,label=\"actual\")\n",
        "plt.plot(t,test_predict,'r',label=\"predicted\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HkZjIqml8W4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# __Neural Nets Models__"
      ],
      "metadata": {
        "id": "UqsczRnY3Syk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Neuron](https://drive.google.com/uc?id=10xLgWxoWUpHzX2kxVSE1MvfJ6w10fZrt)\n",
        "\n",
        "Recuperado de: https://devskrol.com/wp-content/uploads/2020/11/neuron-296581_1280.png"
      ],
      "metadata": {
        "id": "48R85oUf_j0h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## __Perceptron__"
      ],
      "metadata": {
        "id": "F6vGw7ZUjJN4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://drive.google.com/uc?id=1J_SWo3N8ydc7vymRavEG_7B3pOsY7S8J)\n"
      ],
      "metadata": {
        "id": "wloF33Mf9Bkr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Originalmente Pensados para problemas de clasificación. \n",
        "\n",
        "El perceptron se compone de tres partes fundamentales: \n",
        "\n",
        "1. Pesos (w_n)\n",
        "2. Sesgo \n",
        "3. Función de Activación\n",
        "\n",
        "\n",
        "__Pesos__: Son asignados aleatoriamente una vez compilado el perceptron y deben ser siempre mayores a 0 Para garantizar la convergencia del metodo de optimización (Stocastic Gradient Descent)\n",
        "\n",
        "__Bias__: Modifica el boundary con el origen de la función sin tener relación con el comportamiento de los inputs. \n",
        "\n",
        "\n",
        "__Función de Activacion__: Permite la toma de decisiones a través de reglas para la asignación del output de la ejecución. Existen varios tipos de función de activación: \n",
        "- Sigmoide\n",
        "- Step Function  \n",
        "\n",
        "\n",
        "\n",
        "Pregunta: \n",
        "\n",
        "- Cómo es la Función que representa el proceso de estimación de Outputs de un Perceptron?"
      ],
      "metadata": {
        "id": "D9RcCtOzAMmc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# __Gradient Descent__"
      ],
      "metadata": {
        "id": "7Woi-uN1F-68"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Descent es un enfoque de optimización en Machine Learning que puede identificar las mejores soluciones para una amplia gama de problemas. Funciona ajustando iterativamente los parámetros para minimizar la función de costo.\n",
        "\n",
        "![](https://drive.google.com/uc?id=1YLwdXitPesJyQ2D-gcJx0kHfJTw55Hqe)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Pregunta: Cual es la condicional de la función de costos para usar como metodo de optimización al Descenso del Gradiente?\n",
        "\n"
      ],
      "metadata": {
        "id": "0UhCvrgEGbQt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# __Base Model__\n",
        "\n",
        "Densely Conected Layers"
      ],
      "metadata": {
        "id": "OywGHOIPCTkc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://drive.google.com/uc?id=1nSRvHK6uLAs1e2mZwkRh1o1U90uEZx1g)"
      ],
      "metadata": {
        "id": "oxaLCBHdCfx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(16, activation=\"relu\"))\n",
        "model.add(layers.Dense(1))\n",
        "model.compile(loss='mse', optimizer='rmsprop', metrics=\"mae\")"
      ],
      "metadata": {
        "id": "zyk5JuIojScw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_x, train_y, epochs=150, validation_data=(test_x, test_y), shuffle=False)"
      ],
      "metadata": {
        "id": "KYd4uPPPkII3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_predict = model.predict(train_x)    \n",
        "test_predict = model.predict(test_x)\n",
        "val_predict = model.predict(val_x)  "
      ],
      "metadata": {
        "id": "NtdyGyzPkZ7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "rmse_train = sqrt(mean_squared_error(train_y, train_predict))\n",
        "rmse_test = sqrt(mean_squared_error(test_y, test_predict))\n",
        "rmse_val = sqrt(mean_squared_error(val_y, val_predict))\n",
        "print('Train RMSE: %.3f' % rmse_train)\n",
        "print('Test RMSE: %.3f' % rmse_test)\n",
        "print('Val RMSE: %.3f' % rmse_val)"
      ],
      "metadata": {
        "id": "e3-aIJ2fkdLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = np.arange(0,len(test_y),1)\n",
        "\n",
        "plt.figure(figsize=(20,4))\n",
        "plt.title(\"Test DataSet\")\n",
        "plt.plot(t,test_y,label=\"actual\")\n",
        "plt.plot(t,test_predict,'r',label=\"predicted\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bApIzkN1kfZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = np.arange(0,len(train_y),1)\n",
        "\n",
        "plt.figure(figsize=(20,4))\n",
        "plt.title(\"Train DataSet\")\n",
        "plt.plot(t,train_y,label=\"actual\")\n",
        "plt.plot(t,train_predict,'r',label=\"predicted\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BAO4v3AgkhoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## __LSTM__ \n",
        "\n",
        "Long Short Term Memory Nets"
      ],
      "metadata": {
        "id": "Utqfuz_NL1xP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Long Short Term Memory (LSTM) es una red neuronal artificial utilizada en los campos de la inteligencia artificial y el aprendizaje profundo. A diferencia de las redes neuronales estándar, LSTM tiene conexiones de retroalimentación. Tal red neuronal recurrente (RNN) puede procesar no solo puntos de datos individuales (como imágenes), sino también secuencias completas de datos (como voz o video). Por ejemplo, LSTM es aplicable a tareas como el reconocimiento de escritura a mano conectado y no segmentado, reconocimiento de voz, traducción automática, control de robots, videojuegos y atención médica. LSTM se ha convertido en la red neuronal más citada del siglo 20.\n",
        "\n",
        "Recuperado de Wikipedia: https://en.wikipedia.org/wiki/Long_short-term_memory"
      ],
      "metadata": {
        "id": "MBR_xFC8yyv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = train_x.reshape((train_x.shape[0], 1, train_x.shape[1]))\n",
        "test_x = test_x.reshape((test_x.shape[0], 1, test_x.shape[1]))\n",
        "val_x = val_x.reshape((val_x.shape[0], 1, val_x.shape[1]))"
      ],
      "metadata": {
        "id": "D76j8y0amwqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "\n",
        "\n",
        "callbacks = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=\"models/lstm.keras\", \n",
        "    save_best_only=True, \n",
        "    monitor=\"val_loss\"\n",
        ")\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(300))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mse', optimizer='rmsprop', metrics=\"mae\")"
      ],
      "metadata": {
        "id": "9dRV98r_L0J9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_x, train_y, epochs=150, validation_data=(test_x, test_y), shuffle=False, callbacks=callbacks)"
      ],
      "metadata": {
        "id": "sFBQKHwSbHpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X7HkgJ9758MS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(\"models/lstm.keras\")"
      ],
      "metadata": {
        "id": "ixggeiqYES0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_predict = model.predict(train_x)    \n",
        "test_predict = model.predict(test_x)\n",
        "val_predict = model.predict(val_x)  "
      ],
      "metadata": {
        "id": "Y5Qb_4kkcsa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "rmse_train = sqrt(mean_squared_error(train_y, train_predict))\n",
        "rmse_test = sqrt(mean_squared_error(test_y, test_predict))\n",
        "print('Train RMSE: %.3f' % rmse_train)\n",
        "print('Test RMSE: %.3f' % rmse_test)"
      ],
      "metadata": {
        "id": "5l2IsgnpeBgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = np.arange(0,len(test_y),1)\n",
        "\n",
        "plt.figure(figsize=(20,4))\n",
        "plt.title(\"Test DataSet\")\n",
        "plt.plot(t,test_y,label=\"actual\")\n",
        "plt.plot(t,test_predict,'r',label=\"predicted\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NyCEgz1_eSrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = np.arange(0,len(train_y),1)\n",
        "\n",
        "plt.figure(figsize=(20,4))\n",
        "plt.title(\"Train DataSet\")\n",
        "plt.plot(t,train_y,label=\"actual\")\n",
        "plt.plot(t,train_predict,'r',label=\"predicted\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bjy8So2wenuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z8TIivE5E8f4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}