{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNsR4GD9X5Edfp4/5Nz+9z/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pimentell/timeSeriesAnalysysAIQ/blob/main/Time_Series_AQI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# __Neural Nets for Time Series Analysis.__"
      ],
      "metadata": {
        "id": "Vs2Sv9mdBWbW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### __Import Modules and Python Dependencies__"
      ],
      "metadata": {
        "id": "qqSjHws-AuqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import datetime \n",
        "import IPython\n",
        "import IPython.display\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "nzDqbP7vBVck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### __Creating Directory and Download Data from Google Drive__"
      ],
      "metadata": {
        "id": "mfO-mrv19sMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf sample_data\n",
        "!gdown 1GN1P7mrqLIIqIIfVtLluCW-s_PSgQf4E\n",
        "!mkdir data\n",
        "!unzip data.zip  -d data "
      ],
      "metadata": {
        "id": "ZJQILC07v6RW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# __Air Quality Data in India (2015 - 2020)__\n",
        "\n",
        "### Multivariate Time Series\n",
        "#### __Import Data__"
      ],
      "metadata": {
        "id": "-IFChY-U9i0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"data/city_day.csv\", parse_dates=True)\n",
        "data['Date'] = data['Date'].apply(pd.to_datetime)\n",
        "data.set_index('Date',inplace=True)"
      ],
      "metadata": {
        "id": "7dyuRVcQyFy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- __PM2.5 (Particulate Matter 2.5-micrometer)__: measured in ug / m3 (micrograms per cubic meter of air)\n",
        "- __PM10 (Particulate Matter 10-micrometer)__: measured in ug / m3 (micrograms per cubic meter of air)\n",
        "- __SO2 (Sulphur Dioxide)__:measured in ug / m3 (micrograms per cubic meter of air)\n",
        "- __NOx (Any Nitric x-oxide)__: measured in ppb (parts per billion)\n",
        "- __NH3 (Ammonia)__: measured in ug / m3 (micrograms per cubic meter of air)\n",
        "- __CO (Carbon Monoxide)__:CO is measured in mg / m3 (milligrams per cubic meter of air)\n",
        "- __O3 (Ozone or Trioxygen)__: O3 is measured in ug / m3 (micrograms per cubic meter of air)\n",
        "\n",
        "- __AQI__: AIR Quality Index\n",
        "![AQI](https://drive.google.com/uc?id=1zdwS3uFmkytjB4xlDOImnbnsVCaDAYzp)"
      ],
      "metadata": {
        "id": "RMzMWE5R_Uph"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### __Calidad del Aire por Ciudad__\n"
      ],
      "metadata": {
        "id": "PYqDs6MKII0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[[\"City\", \"AQI\"]].groupby([\"City\"]).mean().plot.barh(figsize=(20,10))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4qHPr10-IEqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### __Correlaci贸n calidad del aire y variables predictivas__"
      ],
      "metadata": {
        "id": "V9bFSu9iIMVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[data.City == \"Delhi\"] # Solo para nueva Delhi\n",
        "data[[\"AQI\"]].plot(figsize=(20,10))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "46wX1fHrOTHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_corr = data.corr()\\\n",
        "  .reset_index()[[\"index\", \"AQI\"]]\\\n",
        "  .sort_values(by = \"AQI\", ascending=False)\\\n",
        "  .rename(columns={\"index\":\"Variable\"})\n",
        "data_corr = data_corr[data_corr.Variable != \"AQI\"]\n",
        "data_corr.plot.bar(x=\"Variable\", figsize=(20,10))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iKwgHHGoIL0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### __Data Cleaning__"
      ],
      "metadata": {
        "id": "L7mEck8xGbYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Valores nulos por columna\n",
        "# Eliminamos variables que no son necesarias o no se encuentran dentro del calculo del Indice de Calidad del Aire: \n",
        "data = data.drop(columns = [\"Benzene\", \"Toluene\", \"Xylene\", \"City\", \"AQI_Bucket\"])\n",
        "data.isna().mean()"
      ],
      "metadata": {
        "id": "2ldzerbkGeWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " El tratamiento normal para los datos nulos es la imputaci贸n. \n",
        "\n",
        "- Mean\n",
        "- Median\n",
        "- Regression"
      ],
      "metadata": {
        "id": "iQi5DPzxHLZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.fillna(data.mean(), inplace = True)\n",
        "data.isna().mean()"
      ],
      "metadata": {
        "id": "o4b3vptaGuO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "plt.hist2d(data['PM10'], data['AQI'])\n",
        "plt.colorbar()\n",
        "plt.title(\"PM10 VS AQI\")\n",
        "plt.xlabel(\"PM10\")\n",
        "plt.ylabel('AQI')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EkvclEDbVdSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### __Preparaci贸n de los Datos__"
      ],
      "metadata": {
        "id": "2eoRsO-mRc2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.to_csv(\"clean_data.csv\", index = False)\n",
        "\n",
        "with open(\"clean_data.csv\") as f: \n",
        "  clean_data = f.read()\n",
        "\n",
        "lines = clean_data.split(\"\\n\")[:-1]\n",
        "header = lines[0].split(\",\")\n",
        "lines = lines[1:]\n",
        "\n",
        "aqi = np.zeros(len(lines),)\n",
        "raw_variables = np.zeros((len(lines), len(header)-1))\n",
        "\n",
        "for i, line in enumerate(lines): \n",
        "  values = [x for x in line.split(\",\")]\n",
        "  aqi[i] = values[-1]\n",
        "  raw_variables[i,:] = values[:-1]\n",
        "  "
      ],
      "metadata": {
        "id": "gtqKgrC4RgVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_train_samples = int(0.5 * len(raw_variables))\n",
        "num_val_samples = int(0.25 * len(raw_variables))\n",
        "num_test_samples = len(raw_variables) - num_train_samples - num_val_samples\n",
        "\n",
        "print(\"Entradas de entrenamiento: \", num_train_samples)\n",
        "print(\"Entradas de validation: \", num_val_samples)\n",
        "print(\"Entradas de test: \", num_test_samples)\n"
      ],
      "metadata": {
        "id": "-L7kLB2EVs8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizaci贸n de los datos \n",
        "mean = raw_variables[:num_train_samples].mean(axis=0)\n",
        "raw_variables -= mean\n",
        "std = raw_variables[:num_train_samples].std(axis=0)\n",
        "raw_variables /= std\n",
        "raw_variables[0]"
      ],
      "metadata": {
        "id": "wpj4sJFXY6L5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = raw_variables[:num_train_samples]\n",
        "val_x = raw_variables[num_train_samples:num_train_samples + num_val_samples]\n",
        "test_x = raw_variables[num_train_samples + num_val_samples:]"
      ],
      "metadata": {
        "id": "UmsQ__UcW0V4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = aqi[:num_train_samples]\n",
        "val_y = aqi[num_train_samples:num_train_samples + num_val_samples]\n",
        "test_y = aqi[num_train_samples + num_val_samples:]"
      ],
      "metadata": {
        "id": "wAVH4Yr9ab57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# __Basic Linear Regresion__"
      ],
      "metadata": {
        "id": "S2Eka3Y-3UYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "reg = LinearRegression().fit(train_x, train_y)\n",
        "R2 = reg.score(train_x, train_y)\n",
        "print(\"Coeficiente de Determinaci贸n: \", R2)"
      ],
      "metadata": {
        "id": "8u5gD1pczGP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_predict = reg.predict(train_x)\n",
        "test_predict = reg.predict(test_x)\n",
        "val_predict = reg.predict(val_x)\n",
        "\n",
        "rmse_train = sqrt(mean_squared_error(train_y, train_predict))\n",
        "rmse_test = sqrt(mean_squared_error(test_y, test_predict))\n",
        "print('Train RMSE: %.3f' % rmse_train)\n",
        "print('Test RMSE: %.3f' % rmse_test)"
      ],
      "metadata": {
        "id": "KmneEu0Y0cbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = np.arange(0,len(test_y),1)\n",
        "\n",
        "plt.figure(figsize=(20,4))\n",
        "plt.title(\"Test DataSet\")\n",
        "plt.plot(t,test_y,label=\"actual\")\n",
        "plt.plot(t,test_predict,'r',label=\"predicted\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HkZjIqml8W4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# __Neural Nets Models__"
      ],
      "metadata": {
        "id": "UqsczRnY3Syk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Neuron](https://drive.google.com/uc?id=10xLgWxoWUpHzX2kxVSE1MvfJ6w10fZrt)\n",
        "\n",
        "Recuperado de: https://devskrol.com/wp-content/uploads/2020/11/neuron-296581_1280.png"
      ],
      "metadata": {
        "id": "48R85oUf_j0h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## __Perceptron__"
      ],
      "metadata": {
        "id": "F6vGw7ZUjJN4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://drive.google.com/uc?id=1J_SWo3N8ydc7vymRavEG_7B3pOsY7S8J)\n"
      ],
      "metadata": {
        "id": "wloF33Mf9Bkr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Originalmente Pensados para problemas de clasificaci贸n. \n",
        "\n",
        "El perceptron se compone de tres partes fundamentales: \n",
        "\n",
        "1. Pesos (w_n)\n",
        "2. Sesgo \n",
        "3. Funci贸n de Activaci贸n\n",
        "\n",
        "\n",
        "__Pesos__: Son asignados aleatoriamente una vez compilado el perceptron y deben ser siempre mayores a 0 Para garantizar la convergencia del metodo de optimizaci贸n (Stocastic Gradient Descent)\n",
        "\n",
        "__Bias__: Modifica el boundary con el origen de la funci贸n sin tener relaci贸n con el comportamiento de los inputs. \n",
        "\n",
        "\n",
        "__Funci贸n de Activacion__: Permite la toma de decisiones a trav茅s de reglas para la asignaci贸n del output de la ejecuci贸n. Existen varios tipos de funci贸n de activaci贸n: \n",
        "- Sigmoide\n",
        "- Step Function  \n",
        "\n",
        "\n",
        "\n",
        "Pregunta: \n",
        "\n",
        "- C贸mo es la Funci贸n que representa el proceso de estimaci贸n de Outputs de un Perceptron?"
      ],
      "metadata": {
        "id": "D9RcCtOzAMmc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# __Gradient Descent__"
      ],
      "metadata": {
        "id": "7Woi-uN1F-68"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Descent es un enfoque de optimizaci贸n en Machine Learning que puede identificar las mejores soluciones para una amplia gama de problemas. Funciona ajustando iterativamente los par谩metros para minimizar la funci贸n de costo.\n",
        "\n",
        "![](https://drive.google.com/uc?id=1YLwdXitPesJyQ2D-gcJx0kHfJTw55Hqe)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Pregunta: Cual es la condicional de la funci贸n de costos para usar como metodo de optimizaci贸n al Descenso del Gradiente?\n",
        "\n"
      ],
      "metadata": {
        "id": "0UhCvrgEGbQt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# __Base Model__\n",
        "\n",
        "Densely Conected Layers"
      ],
      "metadata": {
        "id": "OywGHOIPCTkc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://drive.google.com/uc?id=1nSRvHK6uLAs1e2mZwkRh1o1U90uEZx1g)"
      ],
      "metadata": {
        "id": "oxaLCBHdCfx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(16, activation=\"relu\"))\n",
        "model.add(layers.Dense(1))\n",
        "model.compile(loss='mse', optimizer='rmsprop', metrics=\"mae\")"
      ],
      "metadata": {
        "id": "zyk5JuIojScw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_x, train_y, epochs=150, validation_data=(test_x, test_y), shuffle=False)"
      ],
      "metadata": {
        "id": "KYd4uPPPkII3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_predict = model.predict(train_x)    \n",
        "test_predict = model.predict(test_x)\n",
        "val_predict = model.predict(val_x)  "
      ],
      "metadata": {
        "id": "NtdyGyzPkZ7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "rmse_train = sqrt(mean_squared_error(train_y, train_predict))\n",
        "rmse_test = sqrt(mean_squared_error(test_y, test_predict))\n",
        "rmse_val = sqrt(mean_squared_error(val_y, val_predict))\n",
        "print('Train RMSE: %.3f' % rmse_train)\n",
        "print('Test RMSE: %.3f' % rmse_test)\n",
        "print('Val RMSE: %.3f' % rmse_val)"
      ],
      "metadata": {
        "id": "e3-aIJ2fkdLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = np.arange(0,len(test_y),1)\n",
        "\n",
        "plt.figure(figsize=(20,4))\n",
        "plt.title(\"Test DataSet\")\n",
        "plt.plot(t,test_y,label=\"actual\")\n",
        "plt.plot(t,test_predict,'r',label=\"predicted\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bApIzkN1kfZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = np.arange(0,len(train_y),1)\n",
        "\n",
        "plt.figure(figsize=(20,4))\n",
        "plt.title(\"Train DataSet\")\n",
        "plt.plot(t,train_y,label=\"actual\")\n",
        "plt.plot(t,train_predict,'r',label=\"predicted\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BAO4v3AgkhoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## __LSTM__ \n",
        "\n",
        "Long Short Term Memory Nets"
      ],
      "metadata": {
        "id": "Utqfuz_NL1xP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Long Short Term Memory (LSTM) es una red neuronal artificial utilizada en los campos de la inteligencia artificial y el aprendizaje profundo. A diferencia de las redes neuronales est谩ndar, LSTM tiene conexiones de retroalimentaci贸n. Tal red neuronal recurrente (RNN) puede procesar no solo puntos de datos individuales (como im谩genes), sino tambi茅n secuencias completas de datos (como voz o video). Por ejemplo, LSTM es aplicable a tareas como el reconocimiento de escritura a mano conectado y no segmentado, reconocimiento de voz, traducci贸n autom谩tica, control de robots, videojuegos y atenci贸n m茅dica. LSTM se ha convertido en la red neuronal m谩s citada del siglo 20.\n",
        "\n",
        "Recuperado de Wikipedia: https://en.wikipedia.org/wiki/Long_short-term_memory"
      ],
      "metadata": {
        "id": "MBR_xFC8yyv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = train_x.reshape((train_x.shape[0], 1, train_x.shape[1]))\n",
        "test_x = test_x.reshape((test_x.shape[0], 1, test_x.shape[1]))\n",
        "val_x = val_x.reshape((val_x.shape[0], 1, val_x.shape[1]))"
      ],
      "metadata": {
        "id": "D76j8y0amwqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "\n",
        "\n",
        "callbacks = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=\"models/lstm.keras\", \n",
        "    save_best_only=True, \n",
        "    monitor=\"val_loss\"\n",
        ")\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(300))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mse', optimizer='rmsprop', metrics=\"mae\")"
      ],
      "metadata": {
        "id": "9dRV98r_L0J9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_x, train_y, epochs=150, validation_data=(test_x, test_y), shuffle=False, callbacks=callbacks)"
      ],
      "metadata": {
        "id": "sFBQKHwSbHpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X7HkgJ9758MS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(\"models/lstm.keras\")"
      ],
      "metadata": {
        "id": "ixggeiqYES0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_predict = model.predict(train_x)    \n",
        "test_predict = model.predict(test_x)\n",
        "val_predict = model.predict(val_x)  "
      ],
      "metadata": {
        "id": "Y5Qb_4kkcsa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "rmse_train = sqrt(mean_squared_error(train_y, train_predict))\n",
        "rmse_test = sqrt(mean_squared_error(test_y, test_predict))\n",
        "print('Train RMSE: %.3f' % rmse_train)\n",
        "print('Test RMSE: %.3f' % rmse_test)"
      ],
      "metadata": {
        "id": "5l2IsgnpeBgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = np.arange(0,len(test_y),1)\n",
        "\n",
        "plt.figure(figsize=(20,4))\n",
        "plt.title(\"Test DataSet\")\n",
        "plt.plot(t,test_y,label=\"actual\")\n",
        "plt.plot(t,test_predict,'r',label=\"predicted\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NyCEgz1_eSrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = np.arange(0,len(train_y),1)\n",
        "\n",
        "plt.figure(figsize=(20,4))\n",
        "plt.title(\"Train DataSet\")\n",
        "plt.plot(t,train_y,label=\"actual\")\n",
        "plt.plot(t,train_predict,'r',label=\"predicted\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bjy8So2wenuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z8TIivE5E8f4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}